package scala.streaming

import org.apache.spark.streaming.{Seconds, StreamingContext}
import org.apache.spark.SparkContext._
import org.apache.spark.streaming.twitter._
import org.apache.spark.SparkConf
import org.apache.spark.HashPartitioner

import org.apache.spark.streaming.dstream.TransformedDStream

import org.apache.log4j.Logger
import org.apache.log4j.Level
import org.apache.spark.storage.StorageLevel

import java.net._
import java.io._
import scala.io._


import scala.io.Source




object WordCount {

	def main(args: Array[String]) {
		if (args.length < 6) {                      //   0               1                2                    3           4     5
			System.err.println("Usage: TopWords <consumer key> <consumer secret> <access token> <access token secret> <IP> <Port>")
			System.exit(1)
		}

		Logger.getLogger("org").setLevel(Level.OFF)
		Logger.getLogger("akka").setLevel(Level.OFF)

		val updateFunc = (values: Seq[Int], state: Option[Int]) => {
			val currentCount = values.sum
			val previousCount = state.getOrElse(0)

			Some(currentCount + previousCount)
		}

		val newUpdateFunc = (iterator: Iterator[(String, Seq[Int], Option[Int])]) => {
			iterator.flatMap(t => updateFunc(t._2, t._3).map(s => (t._1, s)))
		}

		


		val ip = args(4)
		val port = args(5)
		val wordsToPrint = 60
		val sessionTimeout = 50000

		val Array(consumerKey, consumerSecret, accessToken, accessTokenSecret) = args.take(4)
		val tokens = args.take(4)
		val filters = args.drop(6)


		System.setProperty("twitter4j.oauth.consumerKey", consumerKey)
		System.setProperty("twitter4j.oauth.consumerSecret", consumerSecret)
		System.setProperty("twitter4j.oauth.accessToken", accessToken)
		System.setProperty("twitter4j.oauth.accessTokenSecret", accessTokenSecret)


		val sparkConf = new SparkConf().setAppName("Top Words")
		val ssc = new StreamingContext(sparkConf, Seconds(10))
		ssc.checkpoint("./checkpoints/")


		object auth {
			val config = new twitter4j.conf.ConfigurationBuilder()

			.setOAuthConsumerKey(consumerKey)
			.setOAuthConsumerSecret(consumerSecret)
			.setOAuthAccessToken(accessToken)
			.setOAuthAccessTokenSecret(accessTokenSecret)
			.setIncludeMyRetweetEnabled(false)
			.build
		}

		val twitter_auth = new twitter4j.TwitterFactory(auth.config)
		val a = new twitter4j.auth.OAuthAuthorization(auth.config)

		val atwitter : Option[twitter4j.auth.Authorization] =  Some(twitter_auth.getInstance(a).getAuthorization())
		val stream = TwitterUtils.createStream(ssc, atwitter, filters, StorageLevel.MEMORY_ONLY)

		stream.persist(StorageLevel.MEMORY_ONLY)


		//val classify = new Classifier()


//stream.foreachRDD(rdd => rdd.foreach(x => println(x.toString() + "\n")))

		
		val englishTweetMsgs = stream.filter(_.toString().contains("lang=\'en\'"))
		val tweetTextOnly = englishTweetMsgs.map(_.getText())
		val noEmoticons = tweetTextOnly.map(replaceEmoticons(_))
		val replacedWords = noEmoticons.map(replaceUnwantedWords(_))
		val normalisedWords = replacedWords.map(normaliseMessage(_))
		
		normalisedWords.foreachRDD(rdd => rdd.foreach(x => println(x + "\n")))



/*
		//Remove any tweets with empty text tweets, that are sensitive tweets and don't specify english as lang
		val nonNullStream = stream.filter(tweet =>
			tweet.getText().trim().length() > 0 && 
			tweet.toString().contains("\"lang\":\'en\'")
		);


		val textOnly = nonNullStream.map(tweet => tweet.getText().toLowerCase().trim())

	

		val replaced = textOnly.map(replaceWords(_,happyEmojiWords,"happyemoticon")).map(replaceWords(_,sadEmojiWords,"sademoticon")).map(replaceWords(_,profanityWords,"profanity"))


		//Alpha characters only
		val alphaOnly = replaced.flatMap(line =>line.replaceAll("[^a-z ]","").split("[ ]"))

		//Remove any empty words, retweets, http refs, filter words
		val filteredWords = alphaOnly.filter(word=>word.length()>1 && !word.equals("rt") && !word.matches("^http.*") && !filters.contains(word))

		//Remove stop words
		val removedStopWords  = filteredWords.filter(!stopWords.contains(_))

		//Distinct words - count each word per tweet once
		//val distinctWords = removedStopWords

		//Count words
		val wordDstream = removedStopWords.map(x => (x, 1))



		val initialRDD = ssc.sparkContext.parallelize(Array[(String,Int)]()) 

		val stateDstream = wordDstream.updateStateByKey[Int](newUpdateFunc, new HashPartitioner (ssc.sparkContext.defaultParallelism), true, initialRDD)
		val sortedreqs = stateDstream.transform(rdd => rdd.sortByKey(false))


		


		sortedreqs.foreachRDD(rdd=>{
			val s = new Socket(InetAddress.getByName(ip), Integer.parseInt(port))
			//lazy val in = new BufferedSource(s.getInputStream()).getLines()
			val out = new PrintStream(s.getOutputStream())

			var count = 1

			val rdd_arr = rdd.takeOrdered(wordsToPrint)(Ordering[Int].reverse.on(_._2)).map(classify(_,positiveWords,negativeWords)) //.collect()
			//var total = rdd_arr.count()

			var jsonOut = "{\"name\": \"flare\",\"children\":["

			rdd_arr.foreach(item =>{
				jsonOut = jsonOut +  "{\"name\":\"" + item._1 +"\",\"size\": " + item._2 + ",\"type\":\"" + item._3 + "\"}"
				//if (count < total){
				//	count=count+1
					jsonOut = jsonOut + ","
				//}
			})

			jsonOut = jsonOut.replaceAll(",$","")
			jsonOut = jsonOut + "]}\n"
			
			out.println(jsonOut)
			out.flush()
			s.close()
		})

*/

		ssc.start()
		ssc.awaitTermination //OrTimeout(sessionTimeout)
		ssc.stop()
		println("DONE")

	}
}
